\documentclass[12pt]{article}
\input{../../header.tex}

\title{Дискретная математика. Теория}
\author{Александр Сергеев}
\date{}

\begin{document}
\maketitle
\section{Дискретная теория вероятности}
\subsection{Введение}
\textbf{Определение}\\
\textit{Дискретное вероятностное пространство} -- пара $(\Omega, p)$,\\
где $\Omega$ - не более чем счетное множество элементарных исходов\\
$p: \Omega \rto [0, 1], \sum_{\omega \in \Omega} p(\omega) = 1$\\\\
\textbf{Определение}\\
\textit{Событие} -- $A \subset \Omega$\\
\textit{Вероятность события} -- $P(A) = \sum_{a \in A} p(a)$\\\\
\textbf{Определение}\\
События $A$ и $B$ \textit{независимые}, если $P(A \cap B) = P(A)P(B)$\\\\
$P(B|A) = \frac{P(A \cap B)}{P(A)}$ - вероятность $B$ при условии $A$\\\\
\textbf{Лемма}\\
Если $A$ и $B$ независимы, то $P(B|A) = P(B)$\\\\
\textbf{Определение}\\
Пусть $(\Omega_1, p_1), (\Omega_2, p_2)$ - независимые ДВП\\
Тогда их произведение $(\Omega = \Omega_1 \times \Omega_2, p(\omega_1 \in \Omega_1, \omega_2 \in \Omega_2) = p_1(\omega_1)p_2(\omega_2))$\\\\
\textbf{Определение}\\
$A_1, A_2, \ldots, A_n$ - \textit{независимы в совокупности},\\
если $\fall I \subset \{1\ldots n\}\ P(\bigcap_{i\in I} A_i) = \prod_{i\in I}P(A_i)$\\\\
\textbf{Теорема}\\
$P(B) = \sum_{i = 1}^n P(B|A_i)P(A_i)$\\\\
\textbf{Формула Байеса}\\
$P(A_i|B) = \frac{P(B|A_i)P(A_i)}{P(B)} = \frac{P(B|A_i)P(A_i)}{\sum_{j = 1}^n P(B|A_j)P(A_j)}$\\\\
\textbf{Оффтоп}\\
Рассмотрим пример: выкинули два честных кубика\\
Заметим, что возможно построить две математические модели:
\begin{enumerate}
    \item Результаты - упорядоченная пара $\lan x, y \ran$\\
    Тогда $|\Omega| = 36, p(w) = \frac{1}{36}$
    \item Результаты - неупорядоченная пара $[ x, y ]$\\
    Тогда $|\Omega| = 21, p([x,x]) = \frac{1}{36}, p([x,y\neq x]) = \frac{1}{18}$
\end{enumerate}
Заметим, что для запросов, не содержащих информацию об упорядоченности, результат не зависит от построенной модели
\subsection{Случайные величины}
\textbf{Определение}\\
Случайной величиной называется функция $\xi: \Omega \rto \Rset$\\
\textbf{Примеры случайных величин}
\begin{enumerate}
    \item Пусть кинули 10 монет. Построим случайную величину -- количество выпавших орлов: $\xi(b_1,\ldots,b_n)=b_1+\ldots+b_n$
    \item Пусть кинули n кубиков. Построим случайную величину -- среднее значение: $\xi(v_1,\ldots,v_n)=\frac{v_1+\ldots+v_n}n$
    \item Пусть n студентов приходят на лекцию с вероятностями $p_1, \ldots, p_n$. Построим случайную величину - количество студентов на лекции: $\xi(s_1, \ldots, s_n) = \sum_{i=1}^ns_i$\\
    Заметим, что у этой случайной величины неравномерное распределение вероятностей: $p(s_1,\ldots,s_n) = \prod_{i=1}^n \left\{\begin{array}{ll}
         p_i, & s_i = 1\\
         1-p_i, & s_i = 0
    \end{array}\right.$
\end{enumerate}
Давайте внализировать события через их случайные величины\\
Заметим, что уравнение $\xi = 3$ задает событие $\{w: \xi(w) = 3\}$(аналогично и другие предикаты с $\xi$ задают события)\\
\textbf{Определение}\\
$f_\xi: \Rset \rto \Rset, f_\xi(a) = P(\xi = a)$ -- дискретная плотность распределения\\
$F_\xi: \Rset \rto \Rset, f_\xi(a) = P(\xi \leq a)$ -- функция распределения\\
\textbf{Определение}\\
Пусть $\xi$ -- случайная величина\\
$E_f = \sum_{\omega \in \Omega} \xi(\omega)p(\omega)$ -- математическое ожидание\\
$E_\xi = \sum_{\omega \in \Omega}\xi(\omega)p(\omega) = \sum_a\sum_{\omega: \xi(\omega) = a} = \sum_a a\sum_{\omega: \xi(\omega)=a} p(\omega) = \sum_a aP(\xi = a) = \sum_a af_\xi(a)$\\
\textbf{Определение}\\
$D_\xi = E((\xi-E\xi)^2)$ -- дисперсия\\
\textbf{Свойства математического ожидания}
\begin{enumerate}
    \item $E(c\xi) = cE_\xi$
    \item $E(\xi+\eta) = E_\xi + E_\eta$ (даже для зависимых величин)
    \item Для независимых $\xi, \eta\ E(\xi\eta)=E(\xi)E(\eta)$\\
    \textbf{Доказательство}\\
    $E(\xi\eta) = \sum_a aP(\xi\omega = a) = \sum_x\sum_yxyP(\xi = x \land \omega=y)=\sum_xx\sum_yyP(\xi=x\land\omega=y) = \sum_xx\sum_yyP(\xi=x)P(\omega=y) = \sum_xxP(\xi=x)\sum_yyP(\omega=y)=E_\xi E_\omega$
    \item $E(\xi-E_\xi) = E\xi-EE\xi = E\xi-E\xi=0$
    \item $D_\xi = E((\xi-E\xi)^2)=E(\xi^2-2\xi E\xi + (E\xi)^2)=E(\xi^2)-E(2\xi E\xi)+E((E\xi)^2) = E(\xi^2)-(E\xi)^2$
\end{enumerate}
\textbf{Определение}\\
$\xi, \eta$ независимы, если $\fall a,b$ события $\xi = a$ и $\eta = b$ независимы\\
\textit{Для непрерывных величин вместо $=$ берем $\leq$}\\\\
\textbf{Пример 1}\\
Бросаем два кубика\\
$\xi = v_1 + v_2$\\
$E_\xi = 7$\\
\textbf{Пример 2}\\
Бросаем кубик\\
$\xi=up+down$\\
$E_\xi = 7$\\
\textbf{Пример 3}\\
$\Omega$ -- перестановки $n$ элементов\\
$p(\sigma) = \frac{1}{n!}$\\
$\xi(\sigma)=|\{i: \sigma_i = i\}|$\\
Утверждается, что $E_\xi = 1$\\
Посчитать это через подсчет случаев сложно\\
Несмотря на это, мы можем посчитать матожидание\\
Пусть $\xi_i = (\sigma_i = i)$\\
$\xi = \xi_1 + \ldots + \xi_n$\\
$E_{\xi_i} = P(\xi_i = 1) = \frac{(n-1)!}{n!} = \frac1n$\\
Отсюда $\xi = n\frac1n = 1$\\\\
\textbf{Свойства дисперсии}
$D(c\xi) = c^2 D(\xi)$\\
\textit{\ul{Дисперсия не линейна}}\\\\
\textbf{Теорема}\\
$D(\xi + \eta) = D(\xi) + D(\eta)$\\
\textbf{Доказательство}\\
$D(\xi+\eta) = E(\xi+\eta)^2 - E((\xi+\eta)^2) = E(\xi^2 + 2\xi\eta + \eta^2) - (E\xi)^2 - 2E\xi E\eta - (E\eta)^2 = E\xi^2 + 2E\xi E\eta + E\eta^2 - (E\xi)^2 - 2E\xi E\eta - (E\eta)^2 = E\xi^2 - (E\xi)^2 + E\eta^2 - (E\eta)^2 = D(\xi) + D(\eta)$\\
\textbf{Следствие}\\
$\xi_1, \ldots, \xi_n$ -- одинаково распределенные независимые случайные величины\\
$\xi = \frac1n \sum_{i=1}^n \xi_i$\\
$E_\xi = E_{\xi_i}, D_\xi = \frac1n D_{\xi_i}$\\
\textbf{Определение}\\
$\sigma = \sqrt{D_\xi}$ -- среднеквадратичное отклонение
\subsection{Хвостовые неравенства}
\textbf{Неравенство Маркова}\\
Пусть $\xi \geq 0, E_\xi > 0$\\
Оценим $P(\xi \geq cE_\xi) \leq \frac1c$\\
\textbf{Доказательство}\\
$P(\xi \geq cE_\xi) = \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega)$\\
$E_\xi = \sum_\omega p(\omega)\xi(\omega) = \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega)\xi(\omega) + \us{\xi(\omega) < cE_\xi}{\sum_{\omega}} p(\omega)\xi(\omega) \geq \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega)\xi(\omega) \geq cE_\xi \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega) = cE_\xi P(\xi \geq cE_\xi)$\\
$1 \geq cP(\xi \geq cE_\xi)$\\
$P(\xi \geq cE_\xi) \leq \frac1c$\\\\
\textbf{Неравенство Чебышева}\\
$P(|\xi - E_\xi| \geq c\sqrt{D_\xi}) \leq \frac1{c^2}$  -- относительная форма неравенства Чебышева\\
\textbf{Доказательство}\\
Возьмем $\eta = (\xi - E_\xi)^2$\\
\textbf{Неравентсво Чебышева (ver. 2)}\\
$c := \frac{a}{\sqrt{D_\xi}}$\\
$P(|\xi - E_\xi| \geq a) \leq \frac{D_\xi}{a^2}$ -- абсолютная форма неравенства Чебышева\\\\
\textbf{Пример}\\
Возьмем честную монету\\
$E_\xi = \frac12$\\
$D_\xi = \frac14$\\
$D_\xi = E_\xi - (E_\xi)^2$\\
$P(|\xi - E_\xi| \geq \frac12) \leq 1$\\
$P(|\xi - E_\xi| \geq 1) \leq \frac14$ (на самом деле 0)\\
Видим, что оценка сверху неточная\\\\
\textbf{Пример 2}\\
$\xi_1, \ldots, \xi_n$ -- одинаково распределенные независимые случайные величины\\
$\xi = \frac1n \sum_{i=1}^n \xi_i$\\
$P(|\xi-E_\xi| \geq \varepsilon) \leq \frac{D_\xi}{\varepsilon^2}$\\
$P(|\xi-E_\xi| \geq \varepsilon) \leq \frac{D_{\xi_i}}{n\varepsilon^2}$\\
Пусть мы хотим не попадать в $\varepsilon$-окрестность с вероятностью не более $\delta$ (вероятность промаха)\\
$P(|\xi-E_\xi| < \varepsilon) > 1 - \delta$\\
$P(|\xi-E_\xi| \geq \varepsilon) \leq \delta$\\
Тогда $\frac{D_{\xi_i}}{n\varepsilon^2} \leq \delta$\\
$n \geq \frac{D_{\xi_i}}{\varepsilon^2 \delta} \sim \frac1{\varepsilon^2\delta}$\\
\textbf{Граница Чернова для монеты Бернулли}\\
$P(\xi \geq (1+\delta)np) \leq e^{-\frac{\delta^2}{2+\delta}np}$\\
$P(\xi \leq (1-\delta)np) \leq e^{-\frac{\delta^2}2np}$\\
\textbf{Доказательство}\\
Доказательства не будет, жди теорвер\\
\subsection{Введение в информатику}
\textbf{Определение}\\
\textit{информация} = -неопределенность (по Шеннону)\\\\
Рассмотрим модель случайного источника\\
Пусть есть вероятностное пространство $\Omega$ и распределение $p$\\
Получая событие $\omega$, мы получаем информацию о том, что оно произошло\\
Определим, сколько информации мы получаем\\
Заметим, что оно не зависит от $\Omega$\\
Пусть $H(p_1, p_2, \ldots)$ -- количество информации в зависимости от вероятностей событий\\
$H$ удовлетворяет следующим свойствам:\\
\begin{enumerate}
    \item Для любого числа $n$ $H(p_1, \ldots, p_n)$ -- непрерывно\\
    (т.к. при малом изменении вероятностей количество информации мало изменяется)
    \item $H(\frac1n, \frac1n, \ldots, \frac1n) = h(n)$\\
    $h(n) \uto$ -- (т.к. чем больше вариантов, тем больше информации)
    \item Аддитивность\\
    Пусть $\Omega \subset \Rset^2$ -- множество пар\\
    $A_a = \{ (a,*) \in \Omega \}$\\
    $P(A_a) = p_a$\\
    $P(\{(a,b)\} | A_a) = q_{a,b}$\\
    $p(\{(a,b)\}) = p_a q_{a,b}$\\
    Тогда $H(p_1q_{1,1}, \ldots, p_1q_{1,k_1}, \ldots, p_nq_{n,1}, \ldots, p_nq_{n,k_n}) = H(p_1, \ldots, p_n) + \sum_{i} p_i H(q_{i,1}, \ldots, q_{i,k_i})$
\end{enumerate}
Рассмотрим случай с равными вероятностями\\
$h(nm) = h(n) + \sum_{i=1}^n \frac1n h(m) = h(n) + h(m)$\\
\textbf{Лемма}\\
$h(n) = c\log_2(n)$\\
Традиционно $c=h(2)$ -- бит\\
\textbf{Доказательство}\\
$h(2^k) = kh(2) = ck$\\
Рассмотрим $n^t, n,t \in \Nset$\\
Пусть $2^k \leq n^t < 2^{k+1}$\\
Тогда $h(2^k) \leq h(n^t) \leq h(2^{k+1})$\\
$ck \leq th(n) \leq c(k+1)$\\
$\frac{ck}t \leq h(n) \leq \frac{c(k+1)}t$\\
$k \leq t \log_2 (n) \leq k+1$\\
$\frac{ck}t \leq c \log_2(n) \leq \frac{c(k+1)}t$\\
$|h(n) - c\log_2(n)| \leq \frac ct$ -- при всех $t$\\
Отсюда $h(n) = c \log_2(n)$\\\\
"Разберемся" с $H$\\
Начнем с $p_i, q_i \in \Qset$\\
Пусть $p_i = \frac{a_i}{b}$\\
$k_i = a_i, q_{ij} = \frac1{a_{i}}$\\
Отсюда $H(\frac1b, \ldots, \frac1b) = H(p_1, \ldots, p_n) + \sum_{i=1}^n p_i H(\frac1{a_i}, \ldots, \frac1{a_i}) = H(p_1, \ldots, p_n) + \sum_{i=1}^n c \log_2(a_i)$\\
$H(p_1, \ldots, p_n) = -c(\sum_{i=1}^n p_i\log_2(a_i) - \log_2(b)) = -c(\sum_{i=1}^n p_i\log_2(a_i) - \sum_{i=1}^n p_i\log_2(b)) = -c\sum_{i=1}^n p_i(\log_2 (a_i) - \log_2(b)) = -c\sum_{i=1}^n p_i\log_2 (\frac{a_i}b) = -c\sum_{i=1}^n p_i\log_2 (p_i)$\\
Из непрерывности формула верна для всех $p_i \in \Rset$\\
Выберем $c = 1$ бит\\
Тогда $H = -\sum_{i=1}^n p_i\log_2 (p_i)$ бит\\
Или $H = \sum_{i=1}^n p_i\log_2(\frac1{p_i})$ бит -- энтропия\\
Флешбеш: арифметическое кодирование использует в среднем $H$ бит на каждый символ\\
Отсюда арифметическое кодирование - оптимальное кодирование для данных, которые можно аппроксимировать случайным источником\\
Ограничение в $H$ бит на символ называют \textit{энтропийным барьером}\\
Энтропийный барьер можно преодолеть лишь учетом закономерностей в последовательности символов\\\\
Энтропия Шеннона хорошо описывает случайные последовательности и плохо описывает "регулярные" строки (строчки, имеющие закономерности)\\
Для измерения информации в более сложных объектах используется \textit{Колмогоровская сложность}\\
Колмогоровская сложность зависит от \textit{декодера} и равна количеству информации, необходимому для кодирования объекта\\
$K_A(s) \leq K_B(s) + C_{A,B},$ где $A, B$ -- декодеры, $C$ -- константа\\
$K(s) \leq H(s) + C$\\
\section{Цепи Маркова}
\subsection{Введение}
\textbf{Определение}\\
\textit{Марковская цепь} -- взвешенный ориентированный граф с неотрицательными весами и суммарным весом исходящих ребер, равным 1\\
Пронумеруем состояния (вершины)\\
Пусть $b = \begin{pmatrix} b_1 & b_2 & \ldots & b_n \end{pmatrix}$ -- матрица состояния $B$, где $b_i$ -- вероятность находиться в $i$-ом состоянии ($P(B = i)$)\\
Пусть $c = \begin{pmatrix} c_1 & c_2 & \ldots & c_n \end{pmatrix}$ -- матрица состояния $C$\\
Рассмотрим матрицу переходов $P=(p_{ij})_{n\times n}$, где $p_{ij}$ -- вероятность перейти из $i$ в $j$\\
Найдем зависимость между $b$ и $c$\\
$c_i = P(C = i) = \sum_{j=1}^n P(C=i|B=j)P(B=j) = \sum_{j=1}^n p_{ji}b_j$\\
Отсюда $c = b \cdot P$\\
Тогда распределение вероятностей на $i$-ом шаге $b^i = b^0 P^i$, где $b^0$ -- начальное состояние\\\\
Рассмотрим цепь Маркова как граф\\
Вершина в цепи Маркова называется \textit{состоянием}\\
\textit{Поглощающее(существенное) состояние} -- состояние с кольцевым ребром веса 1\\
Цепь Маркова называется \textit{поглощающей}, если из любого состояния можно попасть в поглощающее\\
Пример непоглощающей цепи: цепь с циклом длины 2 и более, где все ребра веса 1\\
\textit{Эргодический класс} -- компонента сильной связности графа Марковских цепей\\
\textit{Компонента сильной связности} -- максимальное по включению множество вершин, где из каждой можно дойти до каждой\\
(класс эквивалентности для отношения достижимости)\\
Эргодический класс называется \textit{поглощающим}, если из него нет исходящих переходов\\
Цепь Маркова можно представить как граф эргодических классов (но оценить веса ребер не всегда просто)\\
Цепь Маркова называется \textit{эргодической}, если она содержит ровно 1 эргодический класс\\\\
Эргодический класс называется \textit{периодическим с циклом $d$}, если любая длина цикла в этом классе делится на $d > 1$. Иначе -- \textit{регулярной}\\\\
\textbf{Теорема о классификации Марковских цепей}\\
Любая Марковская цепь содержит поглощающие эргодические классы\\
Марковская цепь с вероятностью 1 рано или поздно оказывается в состоянии из поглощающего эргодическим классом\\
Для непериодического поглощающего эргодического класса в случае попадания в него существует предельное распределение вероятностей $b: b = bP$\\
Для любого распределения $b^0\ b^0P^n \rto b$\\\\
Для цепей Маркова существуют две независимые задачи: задача поглощения -- задача определения, в какой поглощающий эргодический класс мы попадем, и задача стационарного распределения внутри поглощающего эргодического класса\\
Займемся задачей поглощения (т.е. определим, в какой эргодический класс мы попадем)\\
В ходе решения этой задачи поглощающие эргодический классы можно заменить на одно поглощающее состояние\\
Занумеруем состояния так, чтобы сначала шли непоглощающие, а потом поглощающие\\
Пусть $1\ldots m$ -- непоглощающие состояния, $m + 1\ldots n$ -- поглощающие\\
Тогда $P = \begin{pmatrix}
    Q & R\\
    \0 & I
\end{pmatrix}$, где \\
$Q = P[1\ldots m][1\ldots m]$\\
$R = P[1\ldots m][m+1\ldots n]$\\
$\0 = P[m+1\ldots n][1\ldots m]$ -- нулевая матрица \\
$I = P[m+1\ldots n][m+1\ldots n]$ -- единичная матрица\\
Возьмем матрицу состояния $b = \begin{pmatrix} b_1 & b_2 & \ldots & b_n \end{pmatrix}$\\
Пусть $a = \begin{pmatrix} b_1 & b_2 & \ldots & b_m \end{pmatrix}$\\
$a^n = a^0 Q^n$\\
\textbf{Лемма}\\
$Q^n \rto \0$\\
\textbf{Доказательство}\\
Пусть $L$ -- максимальная длина кратчайшего пути от $i$ до поглощающей\\
Найдем $X = Q^L$\\
$x_{ij} = \sum_{k_1, k_2, \ldots, k_{L-1}} q_{ik_1}q_{k_1 k_2}\ldots q_{k_{L-1}j}$\\
$\sum_{j \text{-- непогл.}}x_{ij} = \sum_{k_1, k_2, \ldots, k_{L-1}, j} q_{ik_1}q_{k_1 k_2}\ldots q_{k_{L-1}j} = \delta_i < 1$ -- т.к. это вероятность пройти от $i$ до непоглощающего состояния (если бы до любого состояния, то было бы 1)\\
Отсюда $\max_{i=1\ldots m} \sum_{j \text{-- непогл.}}x_{ij} = \max \delta_i = \delta < 1$\\
Тогда $Q^n = Q^L Q^{n-L}$\\
Пусть $\max Q^{n-L} = v_{n-L}$\\
$Q^n_{ij} = (Q^L Q^{n-L})_{ij} = \sum_k Q^L_{ik} Q^{n-L}_{kj} \leq \sum_k Q^L_{ik} v_{n-L} \leq \delta v_{n-L}$\\
$v_n \leq \delta^{\lfloor \frac nL \rfloor} \rto 0$\\
Тогда $Q^n \rto \0$\\
\textbf{Теорема о поглощении}\\
Поглощающая Марковская цепь переходит в состояние поглощения с вероятностью 1\\
\textbf{Доказательство}\\
Следует из леммы\\\\
Научимся определять, где же мы поглотимся\\
Для этого найдем мат. ожидание времени до поглощения\\
$b^0$ -- начальное распределение\\
$T$ -- случайная величина -- число шагов до поглощения\\
$T = \sum_{i=1}^m T_i$, где $T_i$ -- число посещений $i$-ого состояния\\
$T_i = \sum_{j=0}^\infty T_{ij}$, где $T_{ij} = \left\{\begin{array}{ll}
    1, & \text{если на $j$-ом шаге мы в состоянии $i$} \\
    0, & \text{иначе}
\end{array}\right.$\\
\textbf{Лемма}\\
$\sum_{j=0}^\infty Q^j = (I - Q)^{-1}$\\
\textbf{Доказательство}\\
$(I-Q)(I + Q + Q^2 + \ldots + Q^n) = I + Q + Q^2 + \ldots + Q^n - Q - Q^2 - \ldots - Q^{n+1} = I - Q^{n+1} \rto I$\\
\textbf{Определение}\\
$N = (I-Q)^{-1}$ -- фундаментальная матрица поглощения Марковской цепи\\\\
$ET = \sum_{i=1}^m ET_i = \sum_{i=1}^m \sum_{j=0}^\infty ET_{ij} = \sum_{i=1}^m \sum_{j=0}^\infty P(\text{цепь в состоянии $i$ на шаге $j$}) = \sum_{i=1}^m \sum_{j=0}^\infty (a^0 Q^j)_i = \sum_{i=1}^m (\sum_{j=0}^\infty a^0Q^j)_i  = \sum_{i=1}^m (a^0 \sum_{j=0}^\infty Q^j)_i = \sum_{i=1}^m (a^0 N)_i = a^0 N \1$\\
Заметим, что $a^0 N = \begin{pmatrix}
    ET_1 & ET_2 & \ldots & ET_m
\end{pmatrix}$\\\\
$P(\text{погл. в $j$}) = \sum_{i=1}^m P(\text{погл. в $j$ из $i$})P(\text{быть в $j$}) = \sum_{t=0}^\infty \sum_{i=1}^m P(\text{погл. в $j$ из $i$})P(\text{быть в $i$ на шаге $t$}) = \sum_{t=0}^\infty \sum_{i=1}^m R_{i, j-m}P(\text{быть в $i$ на шаге $t$}) = \sum_{i=1}^m R_{i, j-m} \sum_{t=0}^\infty P(\text{быть в $i$ на шаге $t$}) = \sum_{i=1}^m (a^0 N)_i R_{i, j-m} = (a^0 N R)_{j-m}$\\
Отсюда $A=\begin{pmatrix}
    P(\text{погл. в $m+1$}) & P(\text{погл. в $m+2$}) & \ldots & P(\text{погл. в $n$})
\end{pmatrix} = a^0 N R$\\
\textbf{Эргодическая теорема для регулярных цепей}\\
Пусть Марковская цепь такова, что $\fall i, j\ p_{ij} > 0$ (данная цепь непериодическая)\\
Тогда $\ex b\ \fall b^0\ b^0 P^n \rto b$\\
(Отсюда $b = bP$, т.к. $bP = \lim_n bP^{n+1} = \lim_n bP^n = b$)\\
\textbf{Доказательство}\\
Рассмотрим $b^0A$:\\
Предположим, что $\fall j\ a_{ji} = \ot a_i$\\
$(b^0\cdot A)_i = \sum_{j=1}^n b^0_j a_{ji} = \ub{1}{\sum_{j=1}^n b^0_j}\ot a_i = \ot a_i$\\\\
Докажем, что $P^t \rto A: \fall j\ a_{ji} = \ot a_i$\\
Пусть $m_i^n = \min_j (P^t)_{ji}$\\
$M^n_i = \max_j (P^t)_{ji}$\\
\textbf{Лемма}\\
$M^t_i -m^t_i \rto 0$\\
\textbf{Доказательство}\\
$\delta := \min_{ij}p_{ij}, \delta > 0$(из условия теоремы)\\
Рассмотрим $P^{t+1}$:\\
$p^{t+1}_{ji} = \sum_{k=1}^n p_{jk}p_{ki}^t \leq \sum_{k=1, k\neq \nm{posMin}}^n p_{jk}M_i^t + p_{j\nm{posMin}}m_i^t = \ub{1}{\sum_{k=1}^n p_{jk}}M_i^t + p_{j\nm{posMin}}(m_i^t-M_i^t) \leq M_i^t + \delta(m_i^t-M_i^t)$\\
Аналогично $m_i^t + \delta (M^t_i - m_i^t) \leq p_{ji}^{t+1}$\\
Отсюда $M^{t+1}_i - m^{t+1}_i \leq (M_i^t-m_i^t)(1-2\delta) \leq (1-2\delta)^{t+1} \rto 0$\\\\
Научимся искать $b$\\
$bP=b$\\
Заметим, что у данном системы есть одно или бесконечно много решений\\
Утверждается, что $\rg I-P = n-1$\\
Тогда пространство решений одномерное\\
Тогда $\ex! b: \sum_i b = 1$\\\\
Т.о. найти $b$ можно двумя способами:
\begin{enumerate}
    \item $b = b^?\lim_n P^n$, где $b^?$ -- любое начальное состояние
    \item $b: (I-P)b = \0, \sum b_i = 1$ -- СЛОУ
\end{enumerate}
Соединим теоремы:\\
Пусть у нас есть Марковская цепь без периодических классов\\
Для начала представим, что внутри всех поглощающих классов сами состояния являются поглощающими(т.е. удалим внутренние ребра поглощающих классов и добавим петли)\\
Теперь мы можем определить вероятность попадания в каждое состояние каждого поглощающего класса\\
$b^0NR$ -- наше распределение\\
Теперь рассмотрим эргодический класс $A$\\
Пусть $\ot p = \sum_{a\in A}(b^0 NR)_a$\\
$\ot b^0 = \sum_{a\in A}(b^0 NR)_a \vl_A \frac1{\ot p}$ -- начальное состояние внутри эргодического класса $A$\\
По теореме $\ex b: \ot b^0 A^n \rto b$\\
Тогда конечное распределение -- объединение всех $b\ot p$\\
\section{Формальные языки}
\subsection{Конечные автоматы}
Пусть $\Sigma$ -- алфавит\\
$\Sigma^* = \bigcup_{i=0}^\infty \Sigma^i$\\
Тогда $L \subset \Sigma^*$ -- формальный язык\\
Пусть $\epsilon \in \Sigma^0$\\
Задать формальный язык можно 2 способами:
\begin{enumerate}
    \item через порождение (генерация из существующих элементов)
    \item через распознавание (через выделение элементов из множества по некоторому критерию)
\end{enumerate}
\textbf{Спойлер на будущее}\\
Существуют задачи, которые \ul{вообще} не решаются на компьютере\\
Языки делятся на 2 класса (по Хомскому)
\begin{enumerate}
    \item Регулярные языки
    \item Контекстно-свободные языки
\end{enumerate}
\textbf{Определение}\\
Рассмотрим языки в алфавите $\Sigma = \{ c_1, \ldots , c_n \}$: $\varnothing, \{ \epsilon \}, \{ c_1, \}, \{ c_2 \}, \ldots, \{c_n\}$ -- \textit{регулярные языки нулевого уровня} $\nm{Reg}_0$\\
\textit{Регулярные операции} над языками:
\begin{enumerate}
    \item $L, M \mapsto L \cup M$
    \item $L, M \mapsto LM = \{ x: x=yz, y \in L, z \in M \}$ -- конкатенация 
    \item $L \mapsto L^* = \bigcup_{i=0}^\infty L^i$ -- замыкание Клини\\
    Делает из конечного языка бесконечный\\
    $L^0 = \{ \epsilon \}$\\
    $\varnothing^0 = \{\epsilon\}$
\end{enumerate}
Иногда используют запись $abc:=\{abc\}$ (опускают скобки)\\
Также $(abc)^* := \{abc\}^*$\\\\
$\nm{Reg}_1 = \nm{Reg}_0 \cup\{L\cup  M: L,M \in \nm{Reg}_0\} \cup \{LM: L,M \in \nm{Reg}_0\} \cup \{L^*: L \in \nm{Reg}_0\}$\\
$\nm{Reg}_{i+1} = \nm{Reg}_i \cup\{L\cup  M: L,M \in \nm{Reg}_i\} \cup \{LM: L,M \in \nm{Reg}_i\} \cup \{L^*: L \in \nm{Reg}_i\}$\\
Тогда \textit{регулярные языки} -- $\nm{Reg} = \bigcup_{i=0}^\infty \nm{Reg}_i = \lim_{i \rto \infty} \nm{Reg}_i$\\
\textbf{Определение}\\
\textit{Академические регулярные выражения} -- выражения, задающие регулярные языки\\
Пусть $L$ задается $\phi$, $M$ задается $\psi$\\
Тогда $L \cup M$ задается $(\phi)|(\psi)$ (минимальный приоритет операции)\\
$LM$ -- $(\phi)(\psi)$ (средний приоритет операции)\\
$L^*$ -- $(\phi)*$ (максимальный приоритет операции)\\
\textbf{Определение}\\
Конечный автомат -- модель устройства, которое находится в одном из конечного количества состоянии в каждый момент времени\\
Модель задается:
\begin{enumerate}
    \item Множеством состояний $Q$
    \item Алфавитом $\Sigma$
    \item Переходами $\sigma: Q \times \Sigma \rto Q$
    \item Начальным состоянием $S \in Q$
    \item Терминальными (допускающими) состояниями $T \subset Q$ (состояниями, в которых он может находиться в конце)
\end{enumerate}
$L(A) = \{x : A$ допускает $x \}$\\
Если $\ex A: \ub{\text{рег. выр.}}{L(A)} = L$, то $L$ -- автоматный язык, $L \in \nm{Aut}$\\
\subsection{Распознавание}
$\Sigma$ -- алфавит\\
$Q$ -- состояние автомата\\
Пусть $s \in Q, T \subset Q$\\
$\sigma: Q \times \Sigma \rto Q$ -- функция перехода\\
$Q \times \Sigma^*=\nm{Conf}$\\
$\an p, \alpha \vdash \an q \beta$ -- переход от состояния $p$ и строки $\alpha$ к $q, \beta$\\
$c=\alpha[1]$\\
$\alpha = c\beta, \beta = c^{-1}\alpha$\\
$q = \sigma(p, c)$\\
$\vdash \subset \nm{Conf}^2$ -- отношение перехода за один шаг\\
$\vdash^* = \bigcup_{i=0}^\infty \vdash^i$ -- существует путь\\
$L(A) = \{ w: \an sw \}$\\
\textbf{Теорема Клини}\\
Язык регулярный $\LRto \ex$ для него детерменированный конечный автомат\\
\textbf{Определение}\\
Недетерменированный конечный автомат -- автомат, где может быть несколько переходов по одному символу\\
Недетерменированный конечный автомат \textit{допускает} строку $x$, если существует путь, соответствующий $x$ и приводящий к допуску\\
Тогда $\sigma: Q \times \Sigma \rto 2^Q (\bb{P}(Q))$\\
$\an p \alpha \vdash \an q \beta$\\
$\alpha = c\beta$\\
$p \in \delta(p, c)$\\
$L(A) = \{ w: \an sw \vdash^* \an t\epsilon, t \in T \}$\\
\textbf{Теорема}\\
Язык можно задать ДКА $\LRto$ язык можно задать НКА\\
\textbf{Доказательство $\Rto$}\\
ДКА -- ч.с. НКА\\
\textbf{Доказательство $\Lto$}\\
$c=|\Sigma|, 0\ldots z-1$\\
$n=|Q|, 0\ldots n-1$\\
$s$ -- символ\\
$q:= \sigma$
\begin{lstlisting}[language=Python]
    q: int[n][z] #переход
    t: set<int> #хорошие состояния
    def dfa_accept(w):
        cur = s
        for c=0...|w|-1:
            c=w[i]
            cur = q[cur][c]
        return cur in t


    q: set<int>[n][m]
    can[i][u] #можем ли мы, прочитав i символов, попасть в u
    def nfa_accept(w):
        can[0][s]=True
        for i=0...|w|-1:
            c=w[i]
            for u=0...n-1:
                if can[i][u]:
                    for v in q[u][c]:
                        can[i+1][v]=True
        return any(can|w|)
\end{lstlisting}
Пусть у нас был автомат $A_{nfa}=\lan \Sigma, Q, s, T, \sigma\ran$\\
Построим $A_{dfa}=\lan \Sigma, 2^Q, \{s\}, \ot T, \ot \sigma\ran$\\
$\ot T = \{M: M\cap T = \varnothing\}$\\
$\ot \sigma = \bigcup_{u\in M} \sigma(u, c)$\\
Т.о. мы построили ДКА, принимающий наш алфавит\\
(Данный метод -- конструкция подмножеств)\\
Но в такой конструкции многие вершины недостижимы\\
Поэтому вместо нее используют ленивую конструкцию (алгоритм Томпсона)\\\\
Далее добавим в автомат $\epsilon$ переходы и $\epsilon$--НКА\\
$\epsilon$-переход -- переход по пустой строке (не съедает символ)\\
\textbf{Теорема}\\
$A$ распознается $\epsilon$-НКА $\LRto A$ распознается НКА\\
\textbf{Доказательство $\Lto$}\\
Очевидно, т.к. НКА - ч.с. $\epsilon$--НКА\\
\textbf{Доказательство $\Rto$}\\
Применим $\epsilon$-замыкание
\begin{enumerate}
    \item Добавим $\epsilon$-ребро между $p$ и $q$, если между ними есть путь из $\epsilon$ ребер\\
    Теперь мы не делает двух $\epsilon$-переходов подряд
    \item Сделаем терминальное состояние из тех состояний, которые соединены с терминальным $\epsilon$ переходом\\
    Теперь мы не делаем $\epsilon$-переход в конце
    \item Если есть переход $p \xrto{\epsilon} l \xrto{c} q$, добавим ребро $c$ между $p$ и $q$
    Теперь $\epsilon$-переходами можно не пользоваться
    \item Удалим $\epsilon$-переходы
\end{enumerate}
Теперь мы получили эквивалентный НКА\\
\textbf{Доказательство теоремы Клини}
\begin{enumerate}
    \item Докажем $\nm{Reg} \subset \nm{Aut}$\\
    Рассмотрим НКА с одним начальным и одним конечным состоянием\\
    Построим автоматы для $\nm{Reg}_0$ (очев)\\
    Будем строить по индукции\\
    $A \cup B$ -- расположим автоматы параллельно\\
    $AB$ -- расположим автоматы последовательно\\
    $A^*$ -- Пусть $p$, $q$ -- начальное и конечное состояния. Построим $p \xrto{\epsilon} A \xrto{\epsilon} q$, соединим $p \xrto{\epsilon} q, q \xrto{\epsilon} p$
    \item Докажем $\nm{Reg} \supset \nm{Aut}$\\
    Пусть $Q = \{1,\ldots, n\}$\\
    $\xi_{i,j,k}$ -- выражение, переводящее автомат из $i$ в $j$, используя символы с номерами $\leq k$\\
    $\xi_{i,i,0} = \epsilon|c|\ldots$\\
    $\xi_{i,j,0} = c|\ldots$\\
    $\xi_{i,j,k} = \xi_{i,j,k-1} | \xi_{i,k,k-1}\xi^*_{k,k,k-1}\xi_{k,j,k-1}$\\
    Т.о. строки, которые допускает НКА $\phi = \xi_{s_1,t_1,n}|\xi_{s_2,t_2,n}|\ldots,$ где $t_i\in T$, $s_i$ -- начальное состояние
\end{enumerate}
Т.о. мы построили биекцию между автоматами и регулярными выражениями\\
Заметим, что не для всех языков можно построить конечный автомат\\
Докажем, что нельзя построить автомат для ПСП (правильных скобочный последовательностей)\\
\textbf{Утверждение}\\
ПСП -- не регулярный\\
\textbf{Доказательство}\\
Пусть ПСП регулярный, $A$ -- ДКА для ПСП, $n$ -- число состояний $A$\\
Зададим семейства строк:\\
$\begin{array}{cc}
    ( & q_1\\
    (( & q_2\\
    ((( & q_3\\
    \vdots & \vdots\\
    (^{n+1} & q_{n+1}\\
\end{array}$\\
Дадим их нашему автомату\\
Т.к. состояний $n$, а строчек $n+1$, то какие-то две строчки приведут к одинаковому состоянию (по принципу Дирихле)\\
Пусть $q_i$ и $q_j$ приводят к одинаковому состоянию\\
Рассмотрим строчки $x=(^i)^i, y=(^j)^i$\\
Заметим, что автомат допускает $x \LRto$ автомат допускает $y$, но $x$ -- ПСП, а $y$ -- не ПСП\\
\textbf{Лемма о разрастании/накачке}\\
Пусть $L$ -- регулярный\\
Тогда $\ex n > 0:\fall w: w\in L,|w|\geq n\ \ex x,y,z: w=xyz, y\neq \epsilon, |xy|\leq n, \fall k\geq 0\ xy^kz \in L$\\
\textbf{Применение для ПСП}\\
Для фиксированного $n$: $w=(^n)^n, x = (^a, y=(^b, b > 0, z = (^{n-a-b})^n, k = 2, (^{n+b})^n \not\in L$ -- Отсюда ПСП не регулярный\\
\textbf{Доказательство}\\
Пусть $L$ регулярный язык\\
$A$ -- ДКА для $L, n$ -- число состояний\\
Рассмотрим $w \in L, |w| \geq n$\\
Пусть при обработке строки мы прошли по следующему пути:\\
$\rto \ub{n+1}{u_0 \xrto{w_1} u_1 \xrto{w_2} \ldots \xrto{w_n} u_n} \ldots \rto t$\\
Тогда по принципу Дирихле $\ex i\neq j: u_i = u_j$\\
$x:=w[1:i+1], y:= w[i:j+1], z:= w[j+1:]$\\
Тогда $xy^kz$ допустимое $A$\\
\textbf{Определение}\\
Пусть $A$ -- Д.К.А.\\
Состояния $u, v$ -- \textit{различимы} строкой $s$, если:\\
$u \xrto{S} x$\\
$v \xrto{S} y$\\
$x \in T \oplus y \in T$ ($T$ -- терминальные состояния)\\
Состояния $a, b$ эквивалентны($\sim$), если они не различимы никакой строкой $s$\\
$a \sim b$ -- отношение эквивлентности\\
\textbf{Лемма}\\
$u \sim v \Rto \sigma(u,c) \sim \sigma(v,c)$ для любого $c \in \Sigma$\\
($\sigma$ -- переход по символу $c$)\\
\textbf{Доказательство}\\
$\sigma(u,c), \sigma(v,c)$ различимы для $S \Rto u,v$ различимы $cS$\\
\textbf{Алгоритм нахождения неэквивалентных состояний}\\
Пусть $D_k$ -- множество пар состояний, различимых строкой $s: |s| \leq k$
$D_0 = \{(u,v): u \in T \oplus v \in T\}$\\
$D_k = D_{k-1} \cup \{(u,v): \ex c \in \Sigma: (\sigma(u,c), \sigma(v,c) \in D_{k-1}) \}$\\
$D_k = D_{k-1} \Rto D_{k+1} = D_k$\\
Т.к. пар конечное количество, то $\ex k: D_k = D_{k+1}$. Тогда далее все множества $D_{k+i}$ будут равны $D_k$\\
Т.е. мы найдем все пары за конечное время\\
\begin{lstlisting}{python}
    очередь Q
    поместим D0 в Q, D0 в D
    In - множество входящих ребер
    while not Q.empty():            #n^2 раз
        (u,v) = Q.pop()
        for c in Sigma:             #|Sigma| раз
            # Т.к. всего в графе n ребер по символу c, то следующие циклы выполнятся суммарно(по всем итерациям) n^2 раз
            for a in In[u][c]:
                for b in In[v][c]:
                    if (a,b) not in D:
                        Q.push((a,b))
                        D.add((a,b))
\end{lstlisting}
Сложность алгоритма -- $O(n^2|\Sigma|)$\\
\textbf{Теорема}\\
Пусть $A$ -- ДКА для $L$, не содержащий эквивалентных состояний, и все состояния достижимы из стартового\\
Тогда
\begin{enumerate}
    \item $A$ -- минимальный
    \item $A'$ -- ДКА для $L, |Q| = |Q'|$\\
    Тогда $A' \cong A$
\end{enumerate}
\textbf{Доказательство}\\
Рассмотрим автоматы для $L$ -- $A$ и $B$\\
Пусть $A$ -- автомат из теоремы, $B$ содержит меньше состояний\\
Возьмем автомат $A \cup B$, где между $A$ и $B$ нет ребер\\
Хотя в данном автомате 2 стартовых состояния, алгоритм поиска эквивалентных состояний будет работать корректно\\
Заметим, что стартовые состояния в автоматах эквивалентны\\
Пусть в $A$ можно попасть в $u$ из $S_A$(стартового), используя строку $x$\\
Тогда в $B$ $v = \sigma(S_B, x)$ -- эквивалентно $u$\\
Отсюда каждому состоянию из $A$ можно сопоставить состояние из $B$\\
Т.к. в $B$ меньше состояний, то какому-то состоянию в $B$ эквивалентны два состояния из $A$, но тогда они эквивалентны между собой, что противоречит условию $A$\\
Тогда $A$ минимально, ч.т.д.\\
Пусть $A, B$ -- автоматы из теоремы\\
По аналогичным рассуждениям существует биекция между состояниями $A$ и $B$, ч.т.д.
\subsection{Абстрактные штуки}
Рассмотрим $A$ -- множество языков\\
Пусть $A$ -- хорошее, если оно замкнуто относительно регулярных операций, т.е. $R, S \in A \Rto R \cup S \in A, RS \in A, R^* \in A$\\
$\nm{Good}$ -- множество всех хороших языков\\
$\nm{Reg}, \varnothing, 2^{\Sigma^*} \in \nm{Good}$\\
Теперь пусть хорошие языки обязаны содержать $\nm{Reg}_0$\\
Тогда $\varnothing \not\in \nm{Good}$\\
\textbf{Лемма}\\
Пусть $A_\gamma, \gamma \in \Gamma, A_\gamma \in \nm{Good}$\\
Тогда $(\bigcap_{\gamma \in \Gamma} A_\gamma) \in \nm{Good}$\\
\textbf{Теорема}\\
$\bigcap_{A\in \nm{Good}} A = \nm{Reg}$\\
\textbf{Доказательство}\\
Докажем, что $\nm{Reg} \in \bigcap_{A \in \nm{Good}} A$\\
$\fall i\ \fall A \in \nm{Good}\ \nm{Reg}_i \subset A$\\
База: $i = 0$\\
Переход $i \rto i+1$:\\
$T \in \nm{Reg}_{i+1} \Rto T = R\cup S, R, S \in \nm{Reg}_i \Rto R \in A, S \in A \rto T \in A$\\
$\nm{Reg} = \bigcup_{i=0}^m \nm{Reg}_i \subset A \Rto \nm{Reg} \subset A$\\
Докажем $\bigcap_{A \in \nm{Good}} \subset \nm{Reg}$\\
$\nm{Reg} \in \nm{Good}$
\subsection{Решение уравнений в регулярных выражениях}
Решим линейное уравнение в регулярных выражениях\\
$\alpha, \beta$ -- регулярные языки\\
$X$ -- язык\\
$X = \alpha X + \beta, (+) := (|)$\\
$\beta \subset X \Rto \alpha\beta \subset X \Rto \ldots \Rto \alpha^*\beta \subset X$\\
\textbf{Теорема}
\begin{enumerate}
    \item $\epsilon \not\in \alpha$\\
    $X = \alpha^*\beta$
    \item $\epsilon \in \alpha$\\
    $X = \alpha^*\beta|T\ \fall T$
\end{enumerate}
\textbf{Доказательство}\\
Пусть $w \in X, w \not\in \alpha^*\beta, |w| \rto \min$\\
$w \in \alpha X + \beta \Rto w \in \alpha X \Rto w=xy,x\in\alpha,y\in X$\\
Если $\epsilon \not\in \alpha$\\
$|x| > 0 \Rto |y| < |w| \Rto y \in \alpha^* \beta \Rto w \in \alpha^*\beta$\\\\
Решим систему уравнений\\
$\left\{\begin{array}{ll}
    X = \alpha X + \beta Y + \gamma\\
    Y = \xi X + \nu Y + \theta
\end{array}\right.$\\
$\left\{\begin{array}{ll}
    X = \alpha^*(\beta Y + \gamma)\\
    Y = \xi \alpha^*\beta Y + \xi \alpha^* \gamma + \nu Y + \theta
\end{array}\right.$\\
$\left\{\begin{array}{ll}
    X = (\xi \alpha^*\beta + \nu)^*(\xi\alpha^*\gamma + \theta)\\
    Y = \alpha^*\beta(\xi \alpha^* \beta + \nu)^*(\xi\alpha^*\gamma + \theta) + \alpha^*\gamma
\end{array}\right.$\\\\
Решим систему уравнений\\
$\left\{\begin{array}{ll}
    X_1 = \alpha_{11}X_1 + \alpha_{12}X_2 + \ldots + \alpha_{1n}X_n + \beta_1\\
    \vdots
\end{array}\right.$\\
$\left\{\begin{array}{ll}
    X_1 = \alpha_{11}^*(\alpha_{12}X_2 + \ldots + \alpha_{1n}X_n + \beta_1)\\
    \vdots
\end{array}\right.$
\subsection{Свойства регулярных языков}
$R, S \in \nm{Reg}$
\begin{enumerate}
    \item $R\cup S, RS, R^* \in \nm{Reg}$
    \item $R \cap S \in \nm{Reg}$\\
    \textbf{Доказательство}\\
    Воспользуемся "произведением автоматов\\
    Пусть $Q = Q_R \times Q_s$\\
    $\sigma(\an uv, c) = \an{\sigma_R(u,c)}{\sigma_S(v,c)}$\\
    $T = T_R \times T_S$
    \item $\ol R \in \nm{Reg}$, где $T_{\ol R} = T_R^C$
    \item $R_1, \ldots, R_k \in \nm{Reg}$\\
    $f: \bb{B}^k \rto \bb{B}$\\
    $f(R_1,\ldots, R_k) = \{w| f(w_1 \in R_1, \ldots, w_k \in R_k)\}$ -- регулярный
    \item Пусть даны алфавиты $\Sigma, \Pi, f: \Sigma \rto \Pi$\\
    Зададим $f^*:\Sigma^* \rto \Pi^*, f^*(c_1, \ldots, c_n) = f(c_1)f(c_2)\ldots f(c_n)$ -- гомоморфизм\\
    $f^*(\alpha\beta) = f^*(\alpha)f^*(\beta)$\\
    $f = f^*, f(L) = \{f(w), w\in L\}$\\
    Пусть $R \in \nm{Reg}, f := f^*, f(L) = \{f(w)|w\in L\}, R \in \nm{Reg}$\\
    Тогда $f(R) \in \nm{Reg}$
    \item $f^{-1}(L) = \{w| f(w) \in L\}$\\
    Если $R \in \nm{Reg}, f$ -- гомоморфизм\\
    Тогда $f^{-1}(R) \in \nm{Reg}$
\end{enumerate}
\subsection{Алгоритмический анализ регулярных языков}
\begin{enumerate}
    \item $R$ не пуст?\\
    Проверяем, что терминальная вершина достижима из стартовой
    \item $R$ бесконечен?\\
    Ищем цикл в автомате
    \item $R = S?$\\
    Проверяем изоморфность $A^{\min}_R$ и $A^{\min}_S$\\
    Или используем алгоритм поиска эквивалентных состояний
    \item Количество слов длины $l$ в языке $R$\\
    Динамика
\end{enumerate}
\subsection{Контекстно-свободные языки}
Рассмотрим ПСП\\
$\epsilon$ -- ПСП\\
$A,B$ -- ПСП $\Rto AB$ -- ПСП\\
$A$ -- ПСП $\Rto (A)$ -- ПСП\\
Рассмотрим арифметические выражения\\
$F \Rto n$ -- операция максимального приоритета (число)\\
$F \rto -F$\\
$F \rto (E)$\\
$T \rto F$ -- операция умножения\\
$T \rto T * F$\\
$E \rto T$ -- операция сложения\\
$E \rto E + T$\\
$E \rto E - T$\\
\textbf{Определение}\\
Контекстно-свободная грамматика:\\
$\Sigma$ -- алфавит (терминалы)\\
$N$ -- множество переменных (нетерминалы)\\
$S \in N$ -- стартовый нетерминал\\
$P$ -- правила\\
$P \subset \ub{\text{левая часть}}N\times \ub{\text{правая часть}}{(\Sigma\cup N)^*}$\\
Для ПСП:\\
$\Sigma = \{ (,)\}$\\
$N = \{S\}$\\
$S = S$\\
Получим строчку $(())()$\\
$S \Rto SS \Rto (S)S \Rto ((S))S \Rto (())S \Rto (())(S) \Rto (())()$ -- левосторонний вывод(раскрываем левый нетерминал)\\
$S \Rto SS \Rto S(S) \Rto S() \Rto (S)() \Rto ((S))() \Rto (())()$ -- правосторонний вывод(раскрываем правый нетерминал)\\
Разбор можно изображать в виде дерева\\
Результат -- крона дерева разбора -- получается выводом всех терминалов в порядке слева направо\\
"Контекстно-свободные", потому что правила не зависят от контекста, т.е. того, что находится вокруг\\\\
Пусть $\alpha, \beta \in (\Sigma\cup N)^*$ -- сентенциальная форма предложения\\
//todo что такое $\Rto^*$?\\
$\{x|S\Rto^* x, x \in \Sigma^*\}$ -- язык грамматики\\\\
$\Gamma$ -- К.С.Г.\\
Язык -- К.С., если существует К.С.Г. $\Gamma$\\
Регулярные языки $\subset$ К.С. языки\\
\textbf{Определение}\\
$\Gamma$ -- праволинейная грамматика, если ее правила имеют следующий вид:\\
$A \rto c$\\
$A \rto cB$, где $A,B$ -- нетерминалы, $c$ -- терминал\\
\textbf{Обозначения}\\
$a,b,c,\ldots \in \Sigma$\\
$\ldots, u, v, w, x, y, z \in \Sigma^*$\\
$\alpha, \beta, \beta, \xi, \ldots \in (N\cup \Sigma)^*$\\
$A, B, C, \ldots \in N$\\
\textbf{Теорема}\\
$L$ -- регулярный $\LRto L$ задается праволинейной КСГ\\
\textbf{Доказательство $\Rto$}\\
Рассмотрим автомат\\
Сделаем нетерминальные вершины нетерминалами\\
Если есть переход $A \xrto{c} B$, добавим правило $A \rto cB$\\
Если $A$ терминальная, то добавим правило $A \rto \epsilon$\\
$S$ -- стартовое состояний\\
\textbf{Доказательство $\Lto$}\\
Избавимся от правил $A \rto c$:\\
$A \rto cY, Y \rto \epsilon$\\
Теперь выполним обратное преобразование и получим автомат\\\\
Т.к. грамматик счетное множество, а языков -- несчетное, то не каждый язык можно задать грамматикой\\\\
$0^n1^n2^n$ и $\alpha\alpha$ -- не контекстно-свободные\\
Заметим, что у языка может быть несколько деревьев разбора\\
\textbf{Определение}\\
Грамматика называется однозначной, если у любого слова не более одного дерева разбора\\
Грамматика называется существуенно неоднозначной, если она не имеет однозначной к.с. грамматики\\\\
$A, B$ -- к.с.\\
$A\cup B, AB, A^*$ -- к.с.\\
$\Gamma_A, \Gamma_B$\\
$A^*: S\rto \epsilon, \Sigma\rto AS$\\
$A\cup B: S\rto A, S\rto B$\\
$AB: S\rto AB$\\\\
$A \cap B$ -- необязательно к.с.\\
Пример: $0^n1^n2^m, 0^m1^n2^n$ -- к.с., но $0^n1^n2^m\cap 0^m1^n2^n = 0^n1^n2^n$ -- не к.с.\\
\subsection{Преобразование грамматик. Нормальная форма Хомского}
\textbf{Определение}\\
Нормальная форма Хомского -- грамматика, все правила которого имеют следующий вид:\\
$A \rto BC$\\
$A \rto c$\\
$S \rto \epsilon$, но если это правило есть, $S$ не встречается в правых частях правил\\
Символ грамматики называется бесполезным, если он не может встретиться в корректном выводе\\
Символ бесполезен в следующих двух случаях:
\begin{enumerate}
    \item он недостижимый
    \item он непорождающий (т.е. он не приводит к корректному выводу)
\end{enumerate}
\textbf{Теорема}\\
Если нет недостижимых и порождающих, то все символы полезные\\
Сначала нужно избавиться от непорождающих, а затем от недостижимых (т.к. удаление непорождающих может приводить к появлению недостижимых)\\\\
Научимся приводить грамматику в НФХ\\
Все символы $c$ в правилах, содержащих справа нетерминалы, заменим на $X_c$ и добавим правило $X_c \rto c$\\
Некоторые правила примут вид $A \rto B_1 B_2 B_3 \ldots B_n$\\
Заменим такое правило на $A \rto B_1 B_{2\ldots n}, B_{2\ldots n} \rto B_2 B_{3\ldots n}, \ldots, B_{n-1\ldots n} = B_{n-1}B_n$\\
Теперь избавимся от $\eps$\\
\begin{lstlisting}
while change:
    for A -> a:
        if a consists of e-gen:
            mark A as e-gen
\end{lstlisting}
Мы нашли все $\eps$-порождающие нетерминалы\\
Рассмотрим правило $A\rto BC$\\
Если $B$ -- $\eps$-порождающий: Добавим правило $A\rto C$\\
Если $C$ -- $\eps$-порождающий: Добавим правило $A\rto B$\\
Теперь мы можем удалить все правила $A \rto \eps$\\
Осталось обработать случай $S \rto \eps$, где $S$ -- стартовый\\
Если $S$ -- $\eps$-порождающий:\\
$S'$ -- новый старт\\
$S' \rto S$\\
$S'\rto \eps$\\
Осталось избавиться от цепных правил: $A \rto B$\\
Заметим, что данные правила похожи на $\eps$-переходы в автоматах\\
Выполним аналогичные действия для избавления от них\\
Сначала сделаем транзитивное замыкание:\\
Для правил $B_1 \rto B_2, B_2 \rto B_3, \ldots, B_{n-1}\rto B_n$ добавим правила $B_i \rto B_j, i < j$\\
Теперь в разборе можно избежать двух цепных правил подряд\\
Для правил $A \rto B, B\rto CD$ добавим правило $A \rto CD$\\
Теперь цепными правилами можно не пользоваться. Удалим их\\
Заметим, что действия надо выполнять в данном порядке\\
\textbf{Алгоритм Кока-Янгера-Касами (для разбора грамматики в НФХ)}\\
Дана КС $\Gamma$ в НФХ и слово $\omega$\\
Нужно проверить, принадлежит ли слово грамматике\\
$dp_A[l][r] = \left\{\begin{array}{ll}
    1, & A \Rto^* \omega[l,r)\\
    0, & \text{иначе}
\end{array}\right.$\\
Если в грамматике есть правило $A\rto c, \omega[i] = c$, то $dp_A[i][i+1] = 1$\\
$dp_A[l][r] = \bigvee_{A\rto BC}\bigvee_{k=l+1}^{r-1} dp_B[l][k] \land dp_C[k][r]$\\
Вычисления нужно проводить по возрастанию $r-l$\\
Ответ в $dp_S[0][n]$\\
$|\Gamma|$ -- размер грамматики (количество правил)\\
Сложность алгоритма $O(|\Gamma| n^3)$
\subsection{Автомат с магазинной памятью (стек-машина)}
Ребра автомата имеют вид <что на входе>,<что берем со стека>/<что кладем в стек>\\
$Z_0$ -- маркер дна, лежащий на дне стека\\
Математическая модель МП-автомат\\
$\Sigma$ -- входной алфавит\\
$\Pi$ -- стековый алфавит\\
$Z_0 \in \Pi\setminus \Sigma$ -- маркер дна\\
$Q$ -- состояния\\
$s \in Q$ -- стартовое состояние\\
$T \subset Q$ -- терминальные состояния\\
$\delta: Q \times (\Sigma \cup \epsilon) \times \Pi \rto \bb{P}(Q\times \Pi^*)$\\
$\lan q, x, \alpha\ran \vdash \lan \gamma, y, \beta \ran$\\
$x = cy$\\
$\alpha = A\gamma$\\
$\beta = \xi \gamma$\\
$\an \gamma \xi \in \delta(q, c, A)$\\
\textbf{Теорема}\\
КС $\LRto \ex$ МП-автомат
\end{document}
