\documentclass[12pt]{article}
\input{../../header.tex}

\title{Дискретная математика. Теория}
\author{Александр Сергеев}
\date{}

\begin{document}
\maketitle
\section{Дискретная теория вероятности}
\subsection{Введение}
\textbf{Определение}\\
\textit{Дискретное вероятностное пространство} -- пара $(\Omega, p)$,\\
где $\Omega$ - не более чем счетное множество элементарных исходов\\
$p: \Omega \rto [0, 1], \sum_{\omega \in \Omega} p(\omega) = 1$\\\\
\textbf{Определение}\\
\textit{Событие} -- $A \subset \Omega$\\
\textit{Вероятность события} -- $P(A) = \sum_{a \in A} p(a)$\\\\
\textbf{Определение}\\
События $A$ и $B$ \textit{независимые}, если $P(A \cap B) = P(A)P(B)$\\\\
$P(B|A) = \frac{P(A \cap B)}{P(A)}$ - вероятность $B$ при условии $A$\\\\
\textbf{Лемма}\\
Если $A$ и $B$ независимы, то $P(B|A) = P(B)$\\\\
\textbf{Определение}\\
Пусть $(\Omega_1, p_1), (\Omega_2, p_2)$ - независимые ДВП\\
Тогда их произведение $(\Omega = \Omega_1 \times \Omega_2, p(\omega_1 \in \Omega_1, \omega_2 \in \Omega_2) = p_1(\omega_1)p_2(\omega_2))$\\\\
\textbf{Определение}\\
$A_1, A_2, \ldots, A_n)$ - \textit{независимы в совокупности},\\
если $\fall I \subset \{1\ldots n\}\ P(\bigcap_{i\in I} A_i) = \prod_{i\in I}P(A_i)$\\\\
\textbf{Теорема}\\
$P(B) = \sum_{i = 1}^n P(B|A_i)P(A_i)$\\\\
\textbf{Формула Байеса}\\
$P(A_i|B) = \frac{P(B|A_i)P(A_i)}{P(B)} = \frac{P(B|A_i)P(A_i)}{\sum_{j = 1}^n P(B|A_j)P(A_j)}$\\\\
\textbf{Оффтоп}\\
Рассмотрим пример: выкинули два честных кубика\\
Заметим, что возможно построить две математические модели:
\begin{enumerate}
    \item Результаты - упорядоченная пара $\lan x, y \ran$\\
    Тогда $|\Omega| = 36, p(w) = \frac{1}{36}$
    \item Результаты - неупорядоченная пара $[ x, y ]$\\
    Тогда $|\Omega| = 21, p([x,x]) = \frac{1}{36}, p([x,y\neq x]) = \frac{1}{18}$
\end{enumerate}
Заметим, что для запросов, не содержащих информацию об упорядоченности, результат не зависит от построенной модели
\subsection{Случайные величины}
\textbf{Определение}\\
Случайной величиной называется функция $\xi: \Omega \rto \Rset$\\
\textbf{Примеры случайных величин}
\begin{enumerate}
    \item Пусть кинули 10 монет. Построим случайную величину -- количество выпавших орлов: $\xi(b_1,\ldots,b_n)=b_1+\ldots+b_n$
    \item Пусть кинули n кубиков. Построим случайную величину -- среднее значение: $\xi(v_1,\ldots,v_n)=\frac{v_1+\ldots+v_n}n$
    \item Пусть n студентов приходят на лекцию с вероятностями $p_1, \ldots, p_n$. Построим случайную величину - количество студентов на лекции: $\xi(s_1, \ldots, s_n) = \sum_{i=1}^ns_i$\\
    Заметим, что у этой случайной величины неравномерное распределение вероятностей: $p(s_1,\ldots,s_n) = \prod_{i=1}^n \left\{\begin{array}{ll}
         p_i, & s_i = 1\\
         1-p_i, & s_i = 0
    \end{array}\right.$
\end{enumerate}
Давайте внализировать события через их случайные величины\\
Заметим, что уравнение $\xi = 3$ задает событие $\{w: \xi(w) = 3\}$(аналогично и другие предикаты с $\xi$ задают события)\\
\textbf{Определение}\\
$f_\xi: \Rset \rto \Rset, f_\xi(a) = P(\xi = a)$ -- дискретная плотность распределения\\
$F_\xi: \Rset \rto \Rset, f_\xi(a) = P(\xi \leq a)$ -- функция распределения\\
\textbf{Определение}\\
Пусть $\xi$ -- случайная величина\\
$E_f = \sum_{\omega \in \Omega} \xi(\omega)p(\omega)$ -- математическое ожидание\\
$E_\xi = \sum_{\omega \in \Omega}\xi(\omega)p(\omega) = \sum_a\sum_{\omega: \xi(\omega) = a} = \sum_a a\sum_{\omega: \xi(\omega)=a} p(\omega) = \sum_a aP(\xi = a) = \sum_a af_\xi(a)$\\
\textbf{Определение}\\
$D_\xi = E((\xi-E\xi)^2)$ -- дисперсия\\
\textbf{Свойства математического ожидания}
\begin{enumerate}
    \item $E(c\xi) = cE_\xi$
    \item $E(\xi+\eta) = E_\xi + E_\eta$ (даже для зависимых величин)
    \item Для независимых $\xi, \eta\ E(\xi\eta)=E(\xi)E(\eta)$\\
    \textbf{Доказательство}\\
    $E(\xi\eta) = \sum_a aP(\xi\omega = a) = \sum_x\sum_yxyP(\xi = x \land \omega=y)=\sum_xx\sum_yyP(\xi=x\land\omega=y) = \sum_xx\sum_yyP(\xi=x)P(\omega=y) = \sum_xxP(\xi=x)\sum_yyP(\omega=y)=E_\xi E_\omega$
    \item $E(\xi-E_\xi) = E\xi-EE\xi = E\xi-E\xi=0$
    \item $D_\xi = E((\xi-E\xi)^2)=E(\xi^2-2\xi E\xi + (E\xi)^2)=E(\xi^2)-E(2\xi E\xi)+E((E\xi)^2) = E(\xi^2)-(E\xi)^2$
\end{enumerate}
\textbf{Определение}\\
$\xi, \eta$ независимы, если $\fall a,b$ события $\xi = a$ и $\eta = b$ независимы\\
\textit{Для непрерывных величин вместо $=$ берем $\leq$}\\\\
\textbf{Пример 1}\\
Бросаем два кубика\\
$\xi = v_1 + v_2$\\
$E_\xi = 7$\\
\textbf{Пример 2}\\
Бросаем кубик\\
$\xi=up+down$\\
$E_\xi = 7$\\
\textbf{Пример 3}\\
$\Omega$ -- перестановки $n$ элементов\\
$p(\sigma) = \frac{1}{n!}$\\
$\xi(\sigma)=|\{i: \sigma_i = i\}|$\\
Утверждается, что $E_\xi = 1$\\
Посчитать это через подсчет случаев сложно\\
Несмотря на это, мы можем посчитать матожидание\\
Пусть $\xi_i = (\sigma_i = i)$\\
$\xi = \xi_1 + \ldots + \xi_n$\\
$E_{\xi_i} = P(\xi_i = 1) = \frac{(n-1)!}{n!} = \frac1n$\\
Отсюда $\xi = n\frac1n = 1$\\\\
\textbf{Свойства дисперсии}
$D(c\xi) = c^2 D(\xi)$\\
\textit{\ul{Дисперсия не линейна}}\\\\
\textbf{Теорема}\\
$D(\xi + \eta) = D(\xi) + D(\eta)$\\
\textbf{Доказательство}\\
$D(\xi+\eta) = E(\xi+\eta)^2 - E((\xi+\eta)^2) = E(\xi^2 + 2\xi\eta + \eta^2) - (E\xi)^2 - 2E\xi E\eta - (E\eta)^2 = E\xi^2 + 2E\xi E\eta + E\eta^2 - (E\xi)^2 - 2E\xi E\eta - (E\eta)^2 = E\xi^2 - (E\xi)^2 + E\eta^2 - (E\eta)^2 = D(\xi) + D(\eta)$\\
\textbf{Следствие}\\
$\xi_1, \ldots, \xi_n$ -- одинаково распределенные независимые случайные величины\\
$\xi = \frac1n \sum_{i=1}^n \xi_i$\\
$E_\xi = E_{\xi_i}, D_\xi = \frac1n D_{\xi_i}$\\
\textbf{Определение}\\
$\sigma = \sqrt{D_\xi}$ -- среднеквадратичное отклонение
\subsection{Хвостовые неравенства}
\textbf{Неравенство Маркова}\\
Пусть $\xi \geq 0, E_\xi > 0$\\
Оценим $P(\xi \geq cE_\xi) \leq \frac1c$\\
\textbf{Доказательство}\\
$P(\xi \geq cE_\xi) = \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega)$\\
$E_\xi = \sum_\omega p(\omega)\xi(\omega) = \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega)\xi(\omega) + \us{\xi(\omega) < cE_\xi}{\sum_{\omega}} p(\omega)\xi(\omega) \geq \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega)\xi(\omega) \geq cE_\xi \us{\xi(\omega) \geq cE_\xi}{\sum_{\omega}} p(\omega) = cE_\xi P(\xi \geq cE_\xi)$\\
$1 \geq cP(\xi \geq cE_\xi)$\\
$P(\xi \geq cE_\xi) \leq \frac1c$\\\\
\textbf{Неравенство Чебышева}\\
$P(|\xi - E_\xi| \geq c\sqrt{D_\xi}) \leq \frac1{c^2}$  -- относительная форма неравенства Чебышева\\
\textbf{Доказательство}\\
Возьмем $\eta = (\xi - E_\xi)^2$\\
\textbf{Неравентсво Чебышева (ver. 2)}\\
$c := \frac{a}{\sqrt{D_\xi}}$\\
$P(|\xi - E_\xi| \geq a) \leq \frac{D_\xi}{a^2}$ -- абсолютная форма неравенства Чебышева\\\\
\textbf{Пример}\\
Возьмем честную монету\\
$E_\xi = \frac12$\\
$D_\xi = \frac14$\\
$D_\xi = E_\xi - (E_\xi)^2$\\
$P(|\xi - E_\xi| \geq \frac12) \leq 1$\\
$P(|\xi - E_\xi| \geq 1) \leq \frac14$ (на самом деле 0)\\
Видим, что оценка сверху неточная\\\\
\textbf{Пример 2}\\
$\xi_1, \ldots, \xi_n$ -- одинаково распределенные независимые случайные величины\\
$\xi = \frac1n \sum_{i=1}^n \xi_i$\\
$P(|\xi-E_\xi| \geq \varepsilon) \leq \frac{D_\xi}{\varepsilon^2}$\\
$P(|\xi-E_\xi| \geq \varepsilon) \leq \frac{D_{\xi_i}}{n\varepsilon^2}$\\
Пусть мы хотим не попадать в $\varepsilon$-окрестность с вероятностью не более $\delta$ (вероятность промаха)\\
$P(|\xi-E_\xi| < \varepsilon) > 1 - \delta$\\
$P(|\xi-E_\xi| \geq \varepsilon) \leq \delta$\\
Тогда $\frac{D_{\xi_i}}{n\varepsilon^2} \leq \delta$\\
$n \geq \frac{D_{\xi_i}}{\varepsilon^2 \delta} \sim \frac1{\varepsilon^2\delta}$\\
\textbf{Граница Чернова для монеты Бернулли}\\
$P(\xi \geq (1+\delta)np) \leq e^{-\frac{\delta^2}{2+\delta}np}$\\
$P(\xi \leq (1-\delta)np) \leq e^{-\frac{\delta^2}2np}$\\
\textbf{Доказательство}\\
Доказательства не будет, жди теорвер\\
\subsection{Введение в информатику}
\textbf{Определение}\\
\textit{информация} = -неопределенность (по Шеннону)\\\\
Рассмотрим модель случайного источника\\
Пусть есть вероятностное пространство $\Omega$ и распределение $p$\\
Получая событие $\omega$, мы получаем информацию о том, что оно произошло\\
Определим, сколько информации мы получаем\\
Заметим, что оно не зависит от $\Omega$\\
Пусть $H(p_1, p_2, \ldots)$ -- количество информации в зависимости от вероятностей событий\\
$H$ удовлетворяет следующим свойствам:\\
\begin{enumerate}
    \item Для любого числа $n$ $H(p_1, \ldots, p_n)$ -- непрерывно\\
    (т.к. при малом изменении вероятностей количество информации мало изменяется)
    \item $H(\frac1n, \frac1n, \ldots, \frac1n) = h(n)$\\
    $h(n) \uto$ -- (т.к. чем больше вариантов, тем больше информации)
    \item Аддитивность\\
    Пусть $\Omega \subset \Rset^2$ -- множество пар\\
    $A_a = \{ (a,*) \in \Omega \}$\\
    $P(A_a) = p_a$\\
    $P(\{(a,b)\} | A_a) = q_{a,b}$\\
    $p(\{(a,b)\}) = p_a q_{a,b}$\\
    Тогда $H(p_1q_{1,1}, \ldots, p_1q_{1,k_1}, \ldots, p_nq_{n,1}, \ldots, p_nq_{n,k_n}) = H(p_1, \ldots, p_n) + \sum_{i} p_i H(q_{i,1}, \ldots, q_{i,k_i})$
\end{enumerate}
Рассмотрим случай с равными вероятностями\\
$h(nm) = h(n) + \sum_{i=1}^n \frac1n h(m) = h(n) + h(m)$\\
\textbf{Лемма}\\
$h(n) = c\log_2(n)$\\
Традиционно $c=h(2)$ -- бит\\
\textbf{Доказательство}\\
$h(2^k) = kh(2) = ck$\\
Рассмотрим $n^t, n,t \in \Nset$\\
Пусть $2^k \leq n^t < 2^{k+1}$\\
Тогда $h(2^k) \leq h(n^t) \leq h(2^{k+1})$\\
$ck \leq th(n) \leq c(k+1)$\\
$\frac{ck}t \leq h(n) \leq \frac{c(k+1)}t$\\
$k \leq t \log_2 (n) \leq k+1$\\
$\frac{ck}t \leq c \log_2(n) \leq \frac{c(k+1)}t$\\
$|h(n) - c\log_2(n)| \leq \frac ct$ -- при всех $t$\\
Отсюда $h(n) = c \log_2(n)$\\\\
"Разберемся" с $H$\\
Начнем с $p_i, q_i \in \Qset$\\
Пусть $p_i = \frac{a_i}{b}$\\
$k_i = a_i, q_{ij} = \frac1{a_{i}}$\\
Отсюда $H(\frac1b, \ldots, \frac1b) = H(p_1, \ldots, p_n) + \sum_{i=1}^n p_i H(\frac1{a_i}, \ldots, \frac1{a_i}) = H(p_1, \ldots, p_n) + \sum_{i=1}^n c \log_2(a_i)$\\
$H(p_1, \ldots, p_n) = -c(\sum_{i=1}^n p_i\log_2(a_i) - \log_2(b)) = -c(\sum_{i=1}^n p_i\log_2(a_i) - \sum_{i=1}^n p_i\log_2(b)) = -c\sum_{i=1}^n p_i(\log_2 (a_i) - \log_2(b)) = -c\sum_{i=1}^n p_i\log_2 (\frac{a_i}b) = -c\sum_{i=1}^n p_i\log_2 (p_i)$\\
Из непрерывности формула верна для всех $p_i \in \Rset$\\
Выберем $c = 1$ бит\\
Тогда $H = -\sum_{i=1}^n p_i\log_2 (p_i)$ бит\\
Или $H = \sum_{i=1}^n p_i\log_2(\frac1{p_i})$ бит -- энтропия\\
Флешбеш: арифметическое кодирование использует в среднем $H$ бит на каждый символ\\
Отсюда арифметическое кодирование - оптимальное кодирование для данных, которые можно аппроксимировать случайным источником\\
Ограничение в $H$ бит на символ называют \textit{энтропийным барьером}\\
Энтропийный барьер можно преодолеть лишь учетом закономерностей в последовательности символов\\\\
Энтропия Шеннона хорошо описывает случайные последовательности и плохо описывает "регулярные" строки (строчки, имеющие закономерности)\\
Для измерения информации в более сложных объектах используется \textit{Колмогоровская сложность}\\
Колмогоровская сложность зависит от \textit{декодера} и равна количеству информации, необходимому для кодирования объекта\\
$K_A(s) \leq K_B(s) + C_{A,B},$ где $A, B$ -- декодеры, $C$ -- константа\\
$K(s) \leq H(s) + C$\\
\section{Цепи Маркова}
\subsection{Введение}
\textbf{Определение}\\
\textit{Марковская цепь} -- взвешенный ориентированный граф с неотрицательными весами и суммарным весом исходящих ребер, равным 1\\
Пронумеруем состояния (вершины)\\
Пусть $b = \begin{pmatrix} b_1 & b_2 & \ldots & b_n \end{pmatrix}$ -- матрица состояния $B$, где $b_i$ -- вероятность находиться в $i$-ом состоянии ($P(B = i)$)\\
Пусть $c = \begin{pmatrix} c_1 & c_2 & \ldots & c_n \end{pmatrix}$ -- матрица состояния $C$\\
Рассмотрим матрицу переходов $P=(p_{ij})_{n\times n}$, где $p_{ij}$ -- вероятность перейти из $i$ в $j$\\
Найдем зависимость между $b$ и $c$\\
$c_i = P(C = i) = \sum_{j=1}^n P(C=i|B=j)P(B=j) = \sum_{j=1}^n p_{ji}b_j$\\
Отсюда $c = b \cdot P$\\
Тогда распределение вероятностей на $i$-ом шаге $b^i = b^0 P^i$, где $b^0$ -- начальное состояние\\\\
Рассмотрим цепь Маркова как граф\\
Вершина в цепи Маркова называется \textit{состоянием}\\
\textit{Поглощающее(существенное) состояние} -- состояние с кольцевым ребром веса 1\\
Цепь Маркова называется \textit{поглощающей}, если из любого состояния можно попасть в поглощающее\\
Пример непоглощающей цепи: цепь с циклом длины 2 и более, где все ребра веса 1\\
\textit{Эргодический класс} -- компонента сильной связности графа Марковских цепей\\
\textit{Компонента сильной связности} -- максимальное по включению множество вершин, где из каждой можно дойти до каждой\\
(класс эквивалентности для отношения достижимости)\\
Эргодический класс называется \textit{поглощающим}, если из него нет исходящих переходов\\
Цепь Маркова можно представить как граф эргодических классов (но оценить веса ребер не всегда просто)\\
Цепь Маркова называется \textit{эргодической}, если она содержит ровно 1 эргодический класс\\\\
Эргодический класс называется \textit{периодическим с циклом $d$}, если любая длина цикла в этом классе делится на $d > 1$. Иначе -- \textit{регулярной}\\\\
\textbf{Теорема о классификации Марковских цепей}\\
Любая Марковская цепь содержит поглощающие эргодические классы\\
Марковская цепь с вероятностью 1 рано или поздно оказывается в состоянии из поглощающего эргодическим классом\\
Для непериодического поглощающего эргодического класса в случае попадания в него существует предельное распределение вероятностей $b: b = bP$\\
Для любого распределения $b^0\ b^0P^n \rto b$\\\\
Для цепей Маркова существуют две независимые задачи: задача поглощения -- задача определения, в какой поглощающий эргодический класс мы попадем, и задача стационарного распределения внутри поглощающего эргодического класса\\
Займемся задачей поглощения (т.е. определим, в какой эргодический класс мы попадем)\\
В ходе решения этой задачи поглощающие эргодический классы можно заменить на одно поглощающее состояние\\
Занумеруем состояния так, чтобы сначала шли непоглощающие, а потом поглощающие\\
Пусть $1\ldots m$ -- непоглощающие состояния, $m + 1\ldots n$ -- поглощающие\\
Тогда $P = \begin{pmatrix}
    Q & R\\
    \0 & I
\end{pmatrix}$, где \\
$Q = P[1\ldots m][1\ldots m]$\\
$R = P[1\ldots m][m+1\ldots n]$\\
$\0 = P[m+1\ldots n][1\ldots m]$ -- нулевая матрица \\
$I = P[m+1\ldots n][m+1\ldots n]$ -- единичная матрица\\
Возьмем матрицу состояния $b = \begin{pmatrix} b_1 & b_2 & \ldots & b_n \end{pmatrix}$\\
Пусть $a = \begin{pmatrix} b_1 & b_2 & \ldots & b_m \end{pmatrix}$\\
$a^n = a^0 Q^n$\\
\textbf{Лемма}\\
$Q^n \rto \0$\\
\textbf{Доказательство}\\
Пусть $L$ -- максимальная длина кратчайшего пути от $i$ до поглощающей\\
Найдем $X = Q^L$\\
$x_{ij} = \sum_{k_1, k_2, \ldots, k_{L-1}} q_{ik_1}q_{k_1 k_2}\ldots q_{k_{L-1}j}$\\
$\sum_{j \text{-- непогл.}}x_{ij} = \sum_{k_1, k_2, \ldots, k_{L-1}, j} q_{ik_1}q_{k_1 k_2}\ldots q_{k_{L-1}j} = \delta_i < 1$ -- т.к. это вероятность пройти от $i$ до непоглощающего состояния (если бы до любого состояния, то было бы 1)\\
Отсюда $\max_{i=1\ldots m} \sum_{j \text{-- непогл.}}x_{ij} = \max \delta_i = \delta < 1$\\
Тогда $Q^n = Q^L Q^{n-L}$\\
Пусть $\max Q^{n-L} = v_{n-L}$\\
$Q^n_{ij} = (Q^L Q^{n-L})_{ij} = \sum_k Q^L_{ik} Q^{n-L}_{kj} \leq \sum_k Q^L_{ik} v_{n-L} \leq \delta v_{n-L}$\\
$v_n \leq \delta^{\lfloor \frac nL \rfloor} \rto 0$\\
Тогда $Q^n \rto \0$\\
\textbf{Теорема о поглощении}\\
Поглощающая Марковская цепь переходит в состояние поглощения с вероятностью 1\\
\textbf{Доказательство}\\
Следует из леммы\\\\
Научимся определять, где же мы поглотимся\\
Для этого найдем мат. ожидание времени до поглощения\\
$b^0$ -- начальное распределение\\
$T$ -- случайная величина -- число шагов до поглощения\\
$T = \sum_{i=1}^m T_i$, где $T_i$ -- число посещений $i$-ого состояния\\
$T_i = \sum_{j=0}^\infty T_{ij}$, где $T_{ij} = \left\{\begin{array}{ll}
    1, & \text{если на $j$-ом шаге мы в состоянии $i$} \\
    0, & \text{иначе}
\end{array}\right.$\\
\textbf{Лемма}\\
$\sum_{j=0}^\infty Q^j = (I - Q)^{-1}$\\
\textbf{Доказательство}\\
$(I-Q)(I + Q + Q^2 + \ldots + Q^n) = I + Q + Q^2 + \ldots + Q^n - Q - Q^2 - \ldots - Q^{n+1} = I - Q^{n+1} \rto I$\\
\textbf{Определение}\\
$N = (I-Q)^{-1}$ -- фундаментальная матрица поглощения Марковской цепи\\\\
$ET = \sum_{i=1}^m ET_i = \sum_{i=1}^m \sum_{j=0}^\infty ET_{ij} = \sum_{i=1}^m \sum_{j=0}^\infty P(\text{цепь в состоянии $i$ на шаге $j$}) = \sum_{i=1}^m \sum_{j=0}^\infty (a^0 Q^j)_i = \sum_{i=1}^m (\sum_{j=0}^\infty a^0Q^j)_i  = \sum_{i=1}^m (a^0 \sum_{j=0}^\infty Q^j)_i = \sum_{i=1}^m (a^0 N)_i = a^0 N \1$\\
Заметим, что $a^0 N = \begin{pmatrix}
    ET_1 & ET_2 & \ldots & ET_m
\end{pmatrix}$\\\\
$P(\text{погл. в $j$}) = \sum_{i=1}^m P(\text{погл. в $j$ из $i$})P(\text{быть в $j$}) = \sum_{t=0}^\infty \sum_{i=1}^m P(\text{погл. в $j$ из $i$})P(\text{быть в $i$ на шаге $t$}) = \sum_{t=0}^\infty \sum_{i=1}^m R_{i, j-m}P(\text{быть в $i$ на шаге $t$}) = \sum_{i=1}^m R_{i, j-m} \sum_{t=0}^\infty P(\text{быть в $i$ на шаге $t$}) = \sum_{i=1}^m (a^0 N)_i R_{i, j-m} = (a^0 N R)_{j-m}$\\
Отсюда $A=\begin{pmatrix}
    P(\text{погл. в $m+1$}) & P(\text{погл. в $m+2$}) & \ldots & P(\text{погл. в $n$})
\end{pmatrix} = a^0 N R$\\
\textbf{Эргодическая теорема для регулярных цепей}\\
Пусть Марковская цепь такова, что $\fall i, j\ p_{ij} > 0$ (данная цепь непериодическая)\\
Тогда $\ex b\ \fall b^0\ b^0 P^n \rto b$\\
(Отсюда $b = bP$, т.к. $bP = \lim_n bP^{n+1} = \lim_n bP^n = b$)\\
\textbf{Доказательство}\\
Рассмотрим $b^0A$:\\
Предположим, что $\fall j\ a_{ji} = \ot a_i$\\
$(b^0\cdot A)_i = \sum_{j=1}^n b^0_j a_{ji} = \ub{1}{\sum_{j=1}^n b^0_j}\ot a_i = \ot a_i$\\\\
Докажем, что $P^t \rto A: \fall j\ a_{ji} = \ot a_i$\\
Пусть $m_i^n = \min_j (P^t)_{ji}$\\
$M^n_i = \max_j (P^t)_{ji}$\\
\textbf{Лемма}\\
$M^t_i -m^t_i \rto 0$\\
\textbf{Доказательство}\\
$\delta := \min_{ij}p_{ij}, \delta > 0$(из условия теоремы)\\
Рассмотрим $P^{t+1}$:\\
$p^{t+1}_{ji} = \sum_{k=1}^n p_{jk}p_{ki}^t \leq \sum_{k=1, k\neq \nm{posMin}}^n p_{jk}M_i^t + p_{j\nm{posMin}}m_i^t = \ub{1}{\sum_{k=1}^n p_{jk}}M_i^t + p_{j\nm{posMin}}(m_i^t-M_i^t) \leq M_i^t + \delta(m_i^t-M_i^t)$\\
Аналогично $m_i^t + \delta (M^t_i - m_i^t) \leq p_{ji}^{t+1}$\\
Отсюда $M^{t+1}_i - m^{t+1}_i \leq (M_i^t-m_i^t)(1-2\delta) \leq (1-2\delta)^{t+1} \rto 0$\\\\
Научимся искать $b$\\
$bP=b$\\
Заметим, что у данном системы есть одно или бесконечно много решений\\
Утверждается, что $\rg I-P = n-1$\\
Тогда пространство решений одномерное\\
Тогда $\ex! b: \sum_i b = 1$\\\\
Т.о. найти $b$ можно двумя способами:
\begin{enumerate}
    \item $b = \lim_n P^n$
    \item $b: (I-P)b = \0, \sum b_i = 1$ -- СЛОУ
\end{enumerate}
Соединим теоремы:\\
Пусть у нас есть Марковская цепь без периодических классов\\
Для начала представим, что внутри всех поглощающих классов сами состояния являются поглощающими(т.е. удалим внутренние ребра поглощающих классов и добавим петли)\\
Теперь мы можем определить вероятность попадания в каждое состояние каждого поглощающего класса\\
$b^0NR$ -- наше распределение\\
Теперь рассмотрим эргодический класс $A$\\
Пусть $\ot p = \sum_{a\in A}(b^0 NR)_a$\\
$\ot b^0 = \sum_{a\in A}(b^0 NR)_a \vl_A \frac1{\ot p}$ -- начальное состояние внутри эргодического класса $A$\\
По теореме $\ex b: \ot b^0 A^n \rto b$\\
Тогда конечное распределение -- объединение всех $b\ot p$\\
\section{Формальные языки}
\subsection{Конечные автоматы}
Пусть $\Sigma$ -- алфавит\\
$\Sigma^* = \bigcup_{i=0}^\infty \Sigma^i$\\
Тогда $L \subset \Sigma^*$ -- формальный язык\\
Пусть $\epsilon \in \Sigma^0$\\
Задать формальный язык можно 2 способами:
\begin{enumerate}
    \item через порождение (генерация из существующих элементов)
    \item через распознавание (через выделение элементов из множества по некоторому критерию)
\end{enumerate}
\textbf{Спойлер на будущее}\\
Существуют задачи, которые \ul{вообще} не решаются на компьютере\\
Языки делятся на 2 класса (по Хомскому)
\begin{enumerate}
    \item Регулярные языки
    \item Контекстно-свободные языки
\end{enumerate}
\textbf{Определение}\\
Рассмотрим языки в алфавите $\Sigma = \{ c_1, \ldots , c_n \}$: $\varnothing, \{ \epsilon \}, \{ c_1, \}, \{ c_2 \}, \ldots, \{c_n\}$ -- \textit{регулярные языки нулевого уровня} $\nm{Reg}_0$\\
\textit{Регулярные операции} над языками:
\begin{enumerate}
    \item $L, M \mapsto L \cup M$
    \item $L, M \mapsto LM = \{ x: x=yz, y \in L, z \in M \}$ -- конкатенация 
    \item $L \mapsto L^* = \bigcup_{i=0}^\infty L^i$ -- замыкание Клини\\
    Делает из конечного языка бесконечный\\
    $L^0 = \{ \epsilon \}$\\
    $\varnothing^0 = \{\epsilon\}$
\end{enumerate}
Иногда используют запись $abc:=\{abc\}$ (опускают скобки)\\
Также $(abc)^* := \{abc\}^*$\\\\
$\nm{Reg}_1 = \nm{Reg}_0 \cup\{L\cup  M: L,M \in \nm{Reg}_0\} \cup \{LM: L,M \in \nm{Reg}_0\} \cup \{L^*: L \in \nm{Reg}_0\}$\\
$\nm{Reg}_{i+1} = \nm{Reg}_i \cup\{L\cup  M: L,M \in \nm{Reg}_i\} \cup \{LM: L,M \in \nm{Reg}_i\} \cup \{L^*: L \in \nm{Reg}_i\}$\\
Тогда \textit{регулярные языки} -- $\nm{Reg} = \bigcup_{i=0}^\infty \nm{Reg}_i = \lim_{i \rto \infty} \nm{Reg}_i$\\
\textbf{Определение}\\
\textit{Академические регулярные выражения} -- выражения, задающие регулярные языки\\
Пусть $L$ задается $\phi$, $M$ задается $\psi$\\
Тогда $L \cup M$ задается $(\phi)|(\psi)$ (минимальный приоритет операции)\\
$LM$ -- $(\phi)(\psi)$ (средний приоритет операции)\\
$L^*$ -- $(\phi)*$ (максимальный приоритет операции)\\
\textbf{Определение}\\
Модель устройства, которое находится в одном из конечного количества состоянии в каждый момент времени\\
Модель задается:
\begin{enumerate}
    \item Множеством состояний $Q$
    \item Алфавитом $\Sigma$
    \item Переходами $\sigma: Q \times \Sigma \rto Q$
    \item Начальным состоянием $S \in Q$
    \item Терминальными (допускающими) состояниями $T \subset Q$ (состояниями, в которых он может находиться в конце)
\end{enumerate}
$L(A) = \{x : A$ допускает $x \}$\\
Если $\ex A: \ub{\text{рег. выр.}}{L(A)} = L$, то $L$ -- автоматный язык, $L \in \nm{Aut}$\\

\end{document}